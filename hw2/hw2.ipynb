{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл) Создание, разметка корпуса и объяснение того, почему этот текст подходит для оценки (какие моменты вы тут считаете трудными для автоматического посттеггинга и почему, в этом вам может помочь второй ридинг). Не забывайте, что разные теггеры могут использовать разные тегсеты: напишите комментарий о том, какой тегсет вы берёте для разметки и почему.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За основу корпуса я беру стихотворения Велимира Хлебникова. Их особенностью является большое количество придуманных им самим слов. Казалось бы, это не должно препятствовать нашей задаче, т.к. морфемы в его стихотворениях как-раз помогают складывать общий смысл, однако погрешность разметки все равно существенная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r', encoding='utf-8') as fr, open('words.csv', 'w', encoding='utf-8') as fw:\n",
    "    for line in fr:\n",
    "        for word in line.split():\n",
    "            fw.write(word)\n",
    "            fw.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я разметила корпус тегами НКРЯ, так как они кажутся мне удобными, соответственно, теги других парсеров буду выравнивать под формат НКРЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла) Потом вам будет нужно взять три POS теггера для русского языка (udpipe, stanza, natasha, pymorphy, mystem, spacy, deeppavlov) и «прогнать» текст через каждый из них.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*STANZA POS-tagging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (1.4.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: emoji in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (1.7.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (3.19.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (4.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (2.25.1)\n",
      "Requirement already satisfied: six in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (1.21.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from stanza) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from torch>=1.3.0->stanza) (4.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->stanza) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->stanza) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->stanza) (1.26.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from tqdm->stanza) (0.4.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from transformers->stanza) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from transformers->stanza) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from transformers->stanza) (2021.9.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from transformers->stanza) (3.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from transformers->stanza) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from transformers->stanza) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from packaging>=20.0->transformers->stanza) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a2a312655544888a4b73d0cf099262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 22:30:14 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2022-10-11 22:30:17 INFO: File exists: C:\\Users\\varva\\stanza_resources\\ru\\default.zip\n",
      "2022-10-11 22:30:22 INFO: Finished downloading models and saved to C:\\Users\\varva\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce1bdc225654534918ca6afdbb24c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 22:30:44 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "=========================\n",
      "\n",
      "2022-10-11 22:30:44 INFO: Use device: cpu\n",
      "2022-10-11 22:30:44 INFO: Loading: tokenize\n",
      "2022-10-11 22:30:44 INFO: Loading: pos\n",
      "2022-10-11 22:30:45 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "ppln = stanza.Pipeline('ru', processors='tokenize,pos')\n",
    "with open('corpus.txt', 'r', encoding='utf-8') as fr_stanza, open('words_stanza.csv', 'w', encoding='utf-8') as fw_stanza:\n",
    "    doc = ppln(fr_stanza.read())\n",
    "    for snt in doc.sentences:\n",
    "        for word in snt.words:\n",
    "            fw_stanza.write(word.text)\n",
    "            fw_stanza.write(',')\n",
    "            fw_stanza.write(word.upos)\n",
    "            fw_stanza.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PYMORPHY POS-tagging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2[fast] in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pymorphy2[fast]) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pymorphy2[fast]) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'dawg' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for DAWG\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for DAWG did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running install\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'dawg' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "DAWG\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting DAWG>=0.8\n",
      "  Using cached DAWG-0.8.0.tar.gz (371 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: DAWG\n",
      "  Building wheel for DAWG (setup.py): started\n",
      "  Building wheel for DAWG (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for DAWG\n",
      "Failed to build DAWG\n",
      "Installing collected packages: DAWG\n",
      "  Running setup.py install for DAWG: started\n",
      "  Running setup.py install for DAWG: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2[fast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('words.csv', 'r', encoding='utf-8') as fr_pymorphy, open('words_pymorphy.csv', 'w', encoding='utf-8') as fw_pymorphy:\n",
    "    tokens = word_tokenize(fr_pymorphy.read())\n",
    "    for token in tokens:\n",
    "        fw_pymorphy.write(token)\n",
    "        fw_pymorphy.write(' ')\n",
    "        analysis = morph.parse(token)[0]\n",
    "        tag = analysis.tag\n",
    "        fw_pymorphy.write(str(tag))\n",
    "        fw_pymorphy.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NATASHA POS-tagging*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natasha\n",
      "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
      "     ---------------------------------------- 34.4/34.4 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from natasha) (0.9.1)\n",
      "Collecting razdel>=0.5.0\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Collecting ipymarkup>=0.8.0\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting yargy>=0.14.0\n",
      "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.1/41.1 KB 1.9 MB/s eta 0:00:00\n",
      "Collecting navec>=0.9.0\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Collecting slovnet>=0.3.0\n",
      "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 KB 2.6 MB/s eta 0:00:00\n",
      "Collecting intervaltree>=3\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from navec>=0.9.0->natasha) (1.21.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Collecting sortedcontainers<3.0,>=2.0\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py): started\n",
      "  Building wheel for intervaltree (setup.py): finished with status 'done'\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26101 sha256=88a34abbf8f9a74314f3976272097c718a7dc901d7b54970b5f071220a886f9b\n",
      "  Stored in directory: c:\\users\\varva\\appdata\\local\\pip\\cache\\wheels\\45\\23\\de\\5789a92962483fd33cb06674792b9697c1b3766d7c7742830e\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: sortedcontainers, razdel, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 razdel-0.5.0 slovnet-0.5.0 sortedcontainers-2.4.0 yargy-0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "  WARNING: The script razdel-ctl.exe is installed in 'C:\\Users\\varva\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script navec-train.exe is installed in 'C:\\Users\\varva\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\varva\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "names_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r', encoding='utf-8') as fr:\n",
    "    text = fr.read()\n",
    "    doc = Doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocToken(stop=4, text='Росу'),\n",
       " DocToken(start=5, stop=13, text='вишневую'),\n",
       " DocToken(start=14, stop=18, text='меча'),\n",
       " DocToken(start=19, stop=21, text='Ты'),\n",
       " DocToken(start=22, stop=28, text='сушишь')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc.segment(segmenter)\n",
    "display(doc.tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocSent(stop=47, text='Росу вишневую меча\\nТы сушишь волосом волнистым.', tokens=[...]),\n",
       " DocSent(start=48, stop=103, text='А здесь из смеха палача\\nПриходит тот, чей смех н..., tokens=[...]),\n",
       " DocSent(start=104, stop=203, text='То черноглазою гадалкой,\\nМногоглагольная, молчиш..., tokens=[...]),\n",
       " DocSent(start=204, stop=253, text='Он умер, подымая бивни,\\nОпять на небе виден Хорс..., tokens=[...]),\n",
       " DocSent(start=254, stop=306, text='Его живого знали ливни —\\nТеперь он глыба, он зам..., tokens=[...])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc.segment(segmenter)\n",
    "display(doc.sents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocToken(stop=4, text='Росу', pos='ADJ', feats=<Gen,Pos,Masc,Sing>),\n",
       " DocToken(start=5, stop=13, text='вишневую', pos='ADJ', feats=<Gen,Pos,Masc,Sing>),\n",
       " DocToken(start=14, stop=18, text='меча', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=19, stop=21, text='Ты', pos='PRON', feats=<Nom,Sing,2>),\n",
       " DocToken(start=22, stop=28, text='сушишь', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=29, stop=36, text='волосом', pos='ADJ', feats=<Acc,Pos,Fem,Sing>),\n",
       " DocToken(start=37, stop=46, text='волнистым', pos='NOUN', feats=<Inan,Loc,Masc,Sing>),\n",
       " DocToken(start=46, stop=47, text='.', pos='PUNCT'),\n",
       " DocToken(start=48, stop=49, text='А', pos='CCONJ'),\n",
       " DocToken(start=50, stop=55, text='здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=56, stop=58, text='из', pos='ADP'),\n",
       " DocToken(start=59, stop=64, text='смеха', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=65, stop=71, text='палача', pos='NOUN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=72, stop=80, text='Приходит', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Act>),\n",
       " DocToken(start=81, stop=84, text='тот', pos='DET', feats=<Nom,Masc,Sing>),\n",
       " DocToken(start=84, stop=85, text=',', pos='PUNCT'),\n",
       " DocToken(start=86, stop=89, text='чей', pos='DET', feats=<Nom,Masc,Sing>),\n",
       " DocToken(start=90, stop=94, text='смех', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=95, stop=102, text='неистов', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=102, stop=103, text='.', pos='PUNCT'),\n",
       " DocToken(start=104, stop=106, text='То', pos='SCONJ'),\n",
       " DocToken(start=107, stop=118, text='черноглазою', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Act>),\n",
       " DocToken(start=119, stop=127, text='гадалкой', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=127, stop=128, text=',', pos='PUNCT'),\n",
       " DocToken(start=129, stop=144, text='Многоглагольная', pos='PROPN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=144, stop=145, text=',', pos='PUNCT'),\n",
       " DocToken(start=146, stop=153, text='молчишь', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=153, stop=154, text=',', pos='PUNCT'),\n",
       " DocToken(start=155, stop=156, text='А', pos='CCONJ'),\n",
       " DocToken(start=157, stop=159, text='то', pos='SCONJ'),\n",
       " DocToken(start=160, stop=169, text='хохочущей', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Act>),\n",
       " DocToken(start=170, stop=178, text='русалкой', pos='NOUN', feats=<Inan,Nom,Fem,Sing>),\n",
       " DocToken(start=179, stop=181, text='На', pos='ADP'),\n",
       " DocToken(start=182, stop=187, text='бивне', pos='NOUN', feats=<Inan,Loc,Fem,Sing>),\n",
       " DocToken(start=188, stop=195, text='мамонта', pos='NOUN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=196, stop=202, text='сидишь', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Mid>),\n",
       " DocToken(start=202, stop=203, text='.', pos='PUNCT'),\n",
       " DocToken(start=204, stop=206, text='Он', pos='PRON', feats=<Nom,Masc,Sing,3>),\n",
       " DocToken(start=207, stop=211, text='умер', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=211, stop=212, text=',', pos='PUNCT'),\n",
       " DocToken(start=213, stop=220, text='подымая', pos='VERB', feats=<Imp,Nom,Masc,Sing,Past,Part,Act>),\n",
       " DocToken(start=221, stop=226, text='бивни', pos='NOUN', feats=<Inan,Acc,Masc,Plur>),\n",
       " DocToken(start=226, stop=227, text=',', pos='PUNCT'),\n",
       " DocToken(start=228, stop=233, text='Опять', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=234, stop=236, text='на', pos='ADP'),\n",
       " DocToken(start=237, stop=241, text='небе', pos='NOUN', feats=<Inan,Loc,Neut,Sing>),\n",
       " DocToken(start=242, stop=247, text='виден', pos='ADJ', feats=<Pos,Masc,Sing,Short>),\n",
       " DocToken(start=248, stop=252, text='Хорс', pos='PROPN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=252, stop=253, text='.', pos='PUNCT'),\n",
       " DocToken(start=254, stop=257, text='Его', pos='PRON', feats=<Gen,Masc,Sing,3>),\n",
       " DocToken(start=258, stop=264, text='живого', pos='ADJ', feats=<Anim,Acc,Pos,Masc,Sing>),\n",
       " DocToken(start=265, stop=270, text='знали', pos='VERB', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=271, stop=276, text='ливни', pos='NOUN', feats=<Anim,Nom,Masc,Plur>),\n",
       " DocToken(start=277, stop=278, text='—', pos='PUNCT'),\n",
       " DocToken(start=279, stop=285, text='Теперь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=286, stop=288, text='он', pos='PRON', feats=<Nom,Masc,Sing,3>),\n",
       " DocToken(start=289, stop=294, text='глыба', pos='NOUN', feats=<Inan,Nom,Fem,Sing>),\n",
       " DocToken(start=294, stop=295, text=',', pos='PUNCT'),\n",
       " DocToken(start=296, stop=298, text='он', pos='PRON', feats=<Nom,Masc,Sing,3>),\n",
       " DocToken(start=299, stop=305, text='замерз', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=305, stop=306, text='.', pos='PUNCT'),\n",
       " DocToken(start=307, stop=312, text='Здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=313, stop=320, text='скачешь', pos='VERB', feats=<Imp,Ind,Plur,2,Pres,Fin,Act>),\n",
       " DocToken(start=321, stop=323, text='ты', pos='PRON', feats=<Nom,Sing,2>),\n",
       " DocToken(start=323, stop=324, text=',', pos='PUNCT'),\n",
       " DocToken(start=325, stop=330, text='нежна', pos='VERB', feats=<Imp,Imp,Sing,2,Fin,Act>),\n",
       " DocToken(start=330, stop=331, text=',', pos='PUNCT'),\n",
       " DocToken(start=332, stop=335, text='как', pos='SCONJ'),\n",
       " DocToken(start=336, stop=340, text='зной', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=340, stop=341, text=',', pos='PUNCT'),\n",
       " DocToken(start=342, stop=347, text='Среди', pos='ADP'),\n",
       " DocToken(start=348, stop=353, text='ножей', pos='NOUN', feats=<Inan,Gen,Masc,Plur>),\n",
       " DocToken(start=353, stop=354, text=',', pos='PUNCT'),\n",
       " DocToken(start=355, stop=361, text='светла', pos='NOUN', feats=<Inan,Gen,Masc,Plur>),\n",
       " DocToken(start=361, stop=362, text=',', pos='PUNCT'),\n",
       " DocToken(start=363, stop=366, text='как', pos='SCONJ'),\n",
       " DocToken(start=367, stop=372, text='пламя', pos='NOUN', feats=<Inan,Nom,Neut,Sing>),\n",
       " DocToken(start=372, stop=373, text='.', pos='PUNCT'),\n",
       " DocToken(start=374, stop=379, text='Здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=380, stop=385, text='облак', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=386, stop=395, text='выстрелов', pos='NOUN', feats=<Inan,Gen,Masc,Plur>),\n",
       " DocToken(start=396, stop=404, text='сквозной', pos='ADJ', feats=<Gen,Pos,Fem,Sing>),\n",
       " DocToken(start=404, stop=405, text=',', pos='PUNCT'),\n",
       " DocToken(start=406, stop=408, text='Из', pos='ADP'),\n",
       " DocToken(start=409, stop=416, text='мертвых', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=417, stop=420, text='рук', pos='NOUN', feats=<Inan,Gen,Fem,Plur>),\n",
       " DocToken(start=421, stop=426, text='упало', pos='VERB', feats=<Perf,Neut,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=427, stop=432, text='знамя', pos='NOUN', feats=<Inan,Nom,Neut,Sing>),\n",
       " DocToken(start=432, stop=433, text='.', pos='PUNCT'),\n",
       " DocToken(start=434, stop=439, text='Здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=440, stop=442, text='ты', pos='PRON', feats=<Nom,Sing,2>),\n",
       " DocToken(start=443, stop=448, text='поток', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=449, stop=455, text='времен', pos='NOUN', feats=<Inan,Gen,Neut,Plur>),\n",
       " DocToken(start=456, stop=465, text='убыстрила', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=465, stop=466, text=',', pos='PUNCT'),\n",
       " DocToken(start=467, stop=480, text='Скороговоркой', pos='PROPN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=481, stop=486, text='судит', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Act>),\n",
       " DocToken(start=487, stop=492, text='плаха', pos='NOUN', feats=<Anim,Acc,Masc,Sing>),\n",
       " DocToken(start=492, stop=493, text='.', pos='PUNCT'),\n",
       " DocToken(start=494, stop=495, text='А', pos='CCONJ'),\n",
       " DocToken(start=496, stop=501, text='здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=502, stop=510, text='кровавой', pos='ADJ', feats=<Ins,Pos,Fem,Sing>),\n",
       " DocToken(start=511, stop=518, text='жертвой', pos='NOUN', feats=<Anim,Ins,Fem,Sing>),\n",
       " DocToken(start=519, stop=527, text='выстрела', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=528, stop=535, text='Ложится', pos='PROPN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=536, stop=541, text='жизни', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=542, stop=550, text='черепаха', pos='NOUN', feats=<Anim,Nom,Fem,Sing>),\n",
       " DocToken(start=550, stop=551, text='.', pos='PUNCT'),\n",
       " DocToken(start=552, stop=557, text='Здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=558, stop=565, text='красных', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=566, stop=573, text='лебедей', pos='NOUN', feats=<Anim,Gen,Masc,Plur>),\n",
       " DocToken(start=574, stop=578, text='заря', pos='NOUN', feats=<Inan,Nom,Fem,Sing>),\n",
       " DocToken(start=579, stop=587, text='Сверкает', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Pass>),\n",
       " DocToken(start=588, stop=594, text='новыми', pos='ADJ', feats=<Ins,Pos,Plur>),\n",
       " DocToken(start=595, stop=602, text='крылами', pos='NOUN', feats=<Inan,Ins,Masc,Plur>),\n",
       " DocToken(start=602, stop=603, text='.', pos='PUNCT'),\n",
       " DocToken(start=604, stop=607, text='Там', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=608, stop=615, text='надпись', pos='NOUN', feats=<Inan,Acc,Fem,Sing>),\n",
       " DocToken(start=616, stop=623, text='старого', pos='ADJ', feats=<Gen,Pos,Masc,Sing>),\n",
       " DocToken(start=624, stop=628, text='царя', pos='NOUN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=629, stop=637, text='Засыпана', pos='VERB', feats=<Perf,Ins,Plur,Past,Part,Act>),\n",
       " DocToken(start=638, stop=645, text='песками', pos='NOUN', feats=<Inan,Ins,Masc,Plur>),\n",
       " DocToken(start=645, stop=646, text='.', pos='PUNCT'),\n",
       " DocToken(start=647, stop=652, text='Здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=653, stop=660, text='скачешь', pos='VERB', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=661, stop=668, text='вольной', pos='ADJ', feats=<Gen,Pos,Fem,Sing>),\n",
       " DocToken(start=669, stop=678, text='кобылицей', pos='NOUN', feats=<Inan,Ins,Fem,Sing>),\n",
       " DocToken(start=679, stop=681, text='По', pos='ADP'),\n",
       " DocToken(start=682, stop=693, text='семикрылому', pos='ADJ', feats=<Dat,Pos,Masc,Sing>),\n",
       " DocToken(start=694, stop=698, text='пути', pos='NOUN', feats=<Inan,Dat,Masc,Sing>),\n",
       " DocToken(start=698, stop=699, text='.', pos='PUNCT'),\n",
       " DocToken(start=700, stop=705, text='Здесь', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=706, stop=712, text='машешь', pos='VERB', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=713, stop=717, text='алою', pos='ADJ', feats=<Ins,Pos,Fem,Sing>),\n",
       " DocToken(start=718, stop=726, text='столицей', pos='NOUN', feats=<Inan,Ins,Fem,Sing>),\n",
       " DocToken(start=726, stop=727, text=',', pos='PUNCT'),\n",
       " DocToken(start=728, stop=733, text='Точно', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=734, stop=743, text='последнее', pos='ADJ', feats=<Nom,Pos,Neut,Sing>),\n",
       " DocToken(start=744, stop=745, text='«', pos='PUNCT'),\n",
       " DocToken(start=745, stop=751, text='прости', pos='VERB', feats=<Perf,Imp,Sing,2,Fin,Act>),\n",
       " DocToken(start=751, stop=752, text='»', pos='PUNCT'),\n",
       " DocToken(start=752, stop=753, text='.', pos='PUNCT'),\n",
       " DocToken(start=754, stop=760, text='Могилы', pos='NOUN', feats=<Inan,Acc,Fem,Plur>),\n",
       " DocToken(start=761, stop=770, text='вольности', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=771, stop=772, text='—', pos='PUNCT'),\n",
       " DocToken(start=773, stop=782, text='Каргебиль', pos='PROPN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=783, stop=784, text='и', pos='CCONJ'),\n",
       " DocToken(start=785, stop=790, text='Гуниб', pos='PROPN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=791, stop=795, text='Были', pos='AUX', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=796, stop=811, text='соразделителями', pos='VERB', feats=<Perf,Plur,Past,Short,Part,Pass>),\n",
       " DocToken(start=812, stop=814, text='со', pos='ADP'),\n",
       " DocToken(start=815, stop=819, text='мной', pos='PRON', feats=<Ins,Sing,1>),\n",
       " DocToken(start=820, stop=826, text='единых', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=827, stop=833, text='зрелищ', pos='NOUN', feats=<Inan,Gen,Fem,Plur>),\n",
       " DocToken(start=833, stop=834, text=',', pos='PUNCT'),\n",
       " DocToken(start=835, stop=836, text='И', pos='PROPN'),\n",
       " DocToken(start=836, stop=837, text=',', pos='PUNCT'),\n",
       " DocToken(start=838, stop=840, text='за', pos='ADP'),\n",
       " DocToken(start=841, stop=847, text='столом', pos='NOUN', feats=<Inan,Ins,Masc,Sing>),\n",
       " DocToken(start=848, stop=859, text='присутствуя', pos='VERB', feats=<Imp,Pres,Conv,Act>),\n",
       " DocToken(start=859, stop=860, text=',', pos='PUNCT'),\n",
       " DocToken(start=861, stop=864, text='они', pos='PRON', feats=<Nom,Plur,3>),\n",
       " DocToken(start=865, stop=866, text='б', pos='AUX', feats=<Cnd>),\n",
       " DocToken(start=867, stop=870, text='Мне', pos='PRON', feats=<Dat,Sing,1>),\n",
       " DocToken(start=871, stop=873, text='не', pos='PART', feats=<Neg>),\n",
       " DocToken(start=874, stop=885, text='воскликнули', pos='VERB', feats=<Perf,Ind,Sing,2,Fut,Fin,Act>),\n",
       " DocToken(start=886, stop=887, text='б', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=887, stop=888, text=':', pos='PUNCT'),\n",
       " DocToken(start=889, stop=890, text='«', pos='PUNCT'),\n",
       " DocToken(start=890, stop=893, text='Что', pos='PRON', feats=<Inan,Nom,Neut,Sing>),\n",
       " DocToken(start=893, stop=894, text=',', pos='PUNCT'),\n",
       " DocToken(start=895, stop=898, text='что', pos='SCONJ'),\n",
       " DocToken(start=898, stop=899, text=',', pos='PUNCT'),\n",
       " DocToken(start=900, stop=907, text='товарищ', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=907, stop=908, text=',', pos='PUNCT'),\n",
       " DocToken(start=909, stop=915, text='мелешь', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=915, stop=916, text='?', pos='PUNCT'),\n",
       " DocToken(start=916, stop=917, text='»', pos='PUNCT'),\n",
       " DocToken(start=918, stop=922, text='Боец', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=922, stop=923, text=',', pos='PUNCT'),\n",
       " DocToken(start=924, stop=934, text='боровшийся', pos='VERB', feats=<Imp,Nom,Masc,Sing,Past,Part,Act>),\n",
       " DocToken(start=934, stop=935, text=',', pos='PUNCT'),\n",
       " DocToken(start=936, stop=938, text='не', pos='PART', feats=<Neg>),\n",
       " DocToken(start=939, stop=946, text='поборов', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=947, stop=951, text='чуму', pos='NOUN', feats=<Inan,Acc,Fem,Sing>),\n",
       " DocToken(start=951, stop=952, text=',', pos='PUNCT'),\n",
       " DocToken(start=953, stop=956, text='Пал', pos='PROPN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=957, stop=962, text='около', pos='ADP'),\n",
       " DocToken(start=963, stop=969, text='дороги', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=970, stop=980, text='круторогий', pos='ADJ', feats=<Gen,Pos,Masc,Sing>),\n",
       " DocToken(start=981, stop=984, text='бык', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=984, stop=985, text=',', pos='PUNCT'),\n",
       " DocToken(start=986, stop=991, text='Чтобы', pos='SCONJ'),\n",
       " DocToken(start=992, stop=1005, text='невопрошающих', pos='NOUN', feats=<Inan,Nom,Masc,Plur>),\n",
       " DocToken(start=1006, stop=1007, text='—', pos='PUNCT'),\n",
       " DocToken(start=1008, stop=1009, text='к', pos='ADP'),\n",
       " DocToken(start=1010, stop=1014, text='чему', pos='PRON', feats=<Inan,Dat,Neut,Sing>),\n",
       " DocToken(start=1014, stop=1015, text='?', pos='PUNCT'),\n",
       " DocToken(start=1016, stop=1022, text='Узнать', pos='VERB', feats=<Perf,Inf,Act>),\n",
       " DocToken(start=1023, stop=1026, text='дух', pos='NOUN', feats=<Inan,Acc,Masc,Sing>),\n",
       " DocToken(start=1027, stop=1028, text='с', pos='ADP'),\n",
       " DocToken(start=1029, stop=1037, text='радостью', pos='NOUN', feats=<Inan,Ins,Fem,Sing>),\n",
       " DocToken(start=1038, stop=1044, text='владык', pos='NOUN', feats=<Anim,Ins,Masc,Sing>),\n",
       " DocToken(start=1044, stop=1045, text='.', pos='PUNCT'),\n",
       " DocToken(start=1046, stop=1051, text='Когда', pos='SCONJ'),\n",
       " DocToken(start=1052, stop=1057, text='наших', pos='DET', feats=<Inan,Acc,Plur>),\n",
       " DocToken(start=1058, stop=1063, text='коней', pos='NOUN', feats=<Anim,Acc,Masc,Plur>),\n",
       " DocToken(start=1064, stop=1066, text='то', pos='SCONJ'),\n",
       " DocToken(start=1067, stop=1070, text='бег', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1070, stop=1071, text=',', pos='PUNCT'),\n",
       " DocToken(start=1072, stop=1074, text='то', pos='SCONJ'),\n",
       " DocToken(start=1075, stop=1079, text='рысь', pos='NOUN', feats=<Inan,Nom,Fem,Sing>),\n",
       " DocToken(start=1080, stop=1089, text='вспугнули', pos='VERB', feats=<Imp,Fem,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1090, stop=1092, text='их', pos='PRON', feats=<Inan,Acc,Plur,3>),\n",
       " DocToken(start=1092, stop=1093, text=',', pos='PUNCT'),\n",
       " DocToken(start=1094, stop=1098, text='Пару', pos='PROPN', feats=<Inan,Acc,Fem,Sing>),\n",
       " DocToken(start=1099, stop=1115, text='рассеянно-гордых', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=1116, stop=1121, text='орлов', pos='NOUN', feats=<Anim,Gen,Masc,Plur>),\n",
       " DocToken(start=1121, stop=1122, text=',', pos='PUNCT'),\n",
       " DocToken(start=1123, stop=1128, text='Ветер', pos='PROPN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1128, stop=1129, text=',', pos='PUNCT'),\n",
       " DocToken(start=1130, stop=1141, text='неосязуемый', pos='VERB', feats=<Perf,Past,Conv,Mid>),\n",
       " DocToken(start=1142, stop=1145, text='для', pos='ADP'),\n",
       " DocToken(start=1146, stop=1149, text='нас', pos='PRON', feats=<Gen,Plur,1>),\n",
       " DocToken(start=1150, stop=1151, text='и', pos='CCONJ'),\n",
       " DocToken(start=1152, stop=1155, text='тих', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=1155, stop=1156, text=',', pos='PUNCT'),\n",
       " DocToken(start=1157, stop=1164, text='Вздымал', pos='PROPN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1165, stop=1167, text='их', pos='PRON', feats=<Inan,Acc,Plur,3>),\n",
       " DocToken(start=1168, stop=1178, text='царственно', pos='VERB', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=1179, stop=1181, text='на', pos='ADP'),\n",
       " DocToken(start=1182, stop=1188, text='гордый', pos='ADJ', feats=<Inan,Acc,Pos,Masc,Sing>),\n",
       " DocToken(start=1189, stop=1192, text='лов', pos='NOUN', feats=<Inan,Acc,Masc,Sing>),\n",
       " DocToken(start=1192, stop=1193, text='.', pos='PUNCT'),\n",
       " DocToken(start=1194, stop=1203, text='Вселенной', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=1204, stop=1213, text='повинуяся', pos='ADJ', feats=<Dat,Pos,Masc,Sing>),\n",
       " DocToken(start=1214, stop=1219, text='указу', pos='NOUN', feats=<Inan,Dat,Masc,Sing>),\n",
       " DocToken(start=1219, stop=1220, text=',', pos='PUNCT'),\n",
       " DocToken(start=1221, stop=1230, text='Вздымался', pos='PROPN', feats=<Anim,Dat,Masc,Sing>),\n",
       " DocToken(start=1231, stop=1234, text='гор', pos='NOUN', feats=<Inan,Gen,Fem,Plur>),\n",
       " DocToken(start=1235, stop=1238, text='ряд', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1239, stop=1245, text='долгий', pos='ADJ', feats=<Nom,Pos,Masc,Sing>),\n",
       " DocToken(start=1245, stop=1246, text='.', pos='PUNCT'),\n",
       " DocToken(start=1247, stop=1248, text='Я', pos='PRON', feats=<Nom,Sing,1>),\n",
       " DocToken(start=1249, stop=1262, text='путешествовал', pos='VERB', feats=<Imp,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1263, stop=1265, text='по', pos='ADP'),\n",
       " DocToken(start=1266, stop=1273, text='Кавказу', pos='PROPN', feats=<Inan,Dat,Masc,Sing>),\n",
       " DocToken(start=1274, stop=1275, text='И', pos='CCONJ'),\n",
       " DocToken(start=1276, stop=1281, text='думал', pos='VERB', feats=<Imp,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1282, stop=1283, text='о', pos='ADP'),\n",
       " DocToken(start=1284, stop=1291, text='далекой', pos='ADJ', feats=<Loc,Pos,Fem,Sing>),\n",
       " DocToken(start=1292, stop=1297, text='Волге', pos='PROPN', feats=<Inan,Loc,Fem,Sing>),\n",
       " DocToken(start=1297, stop=1298, text='.', pos='PUNCT'),\n",
       " DocToken(start=1299, stop=1303, text='Конь', pos='PROPN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=1303, stop=1304, text=',', pos='PUNCT'),\n",
       " DocToken(start=1305, stop=1312, text='закинув', pos='VERB', feats=<Perf,Nom,Masc,Sing,Past,Part,Act>),\n",
       " DocToken(start=1313, stop=1318, text='резво', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=1319, stop=1322, text='шею', pos='NOUN', feats=<Inan,Acc,Fem,Sing>),\n",
       " DocToken(start=1322, stop=1323, text=',', pos='PUNCT'),\n",
       " DocToken(start=1324, stop=1330, text='Скакал', pos='PROPN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=1331, stop=1333, text='по', pos='ADP'),\n",
       " DocToken(start=1334, stop=1340, text='легкой', pos='ADJ', feats=<Dat,Pos,Fem,Sing>),\n",
       " DocToken(start=1341, stop=1348, text='складке', pos='NOUN', feats=<Inan,Dat,Fem,Sing>),\n",
       " DocToken(start=1349, stop=1355, text='бездны', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=1355, stop=1356, text='.', pos='PUNCT'),\n",
       " DocToken(start=1357, stop=1358, text='С', pos='ADP'),\n",
       " DocToken(start=1359, stop=1365, text='ужасом', pos='NOUN', feats=<Inan,Ins,Neut,Sing>),\n",
       " DocToken(start=1365, stop=1366, text=',', pos='PUNCT'),\n",
       " DocToken(start=1367, stop=1368, text='в', pos='ADP'),\n",
       " DocToken(start=1369, stop=1375, text='борьбе', pos='NOUN', feats=<Inan,Loc,Fem,Sing>),\n",
       " DocToken(start=1376, stop=1385, text='невольной', pos='ADJ', feats=<Ins,Pos,Fem,Sing>),\n",
       " DocToken(start=1386, stop=1393, text='хорошея', pos='NOUN', feats=<Inan,Ins,Fem,Sing>),\n",
       " DocToken(start=1393, stop=1394, text=',', pos='PUNCT'),\n",
       " DocToken(start=1395, stop=1396, text='Я', pos='PRON', feats=<Nom,Sing,1>),\n",
       " DocToken(start=1397, stop=1402, text='думал', pos='VERB', feats=<Imp,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1402, stop=1403, text=',', pos='PUNCT'),\n",
       " DocToken(start=1404, stop=1407, text='что', pos='SCONJ'),\n",
       " DocToken(start=1408, stop=1418, text='заниматься', pos='VERB', feats=<Imp,Inf,Mid>),\n",
       " DocToken(start=1419, stop=1426, text='числами', pos='NOUN', feats=<Inan,Ins,Neut,Plur>),\n",
       " DocToken(start=1427, stop=1430, text='над', pos='ADP'),\n",
       " DocToken(start=1431, stop=1438, text='бездною', pos='NOUN', feats=<Inan,Ins,Masc,Plur>),\n",
       " DocToken(start=1439, stop=1446, text='полезно', pos='ADJ', feats=<Pos,Neut,Sing,Short>),\n",
       " DocToken(start=1446, stop=1447, text='.', pos='PUNCT'),\n",
       " DocToken(start=1448, stop=1456, text='Невольно', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1457, stop=1462, text='числа', pos='NOUN', feats=<Inan,Gen,Neut,Sing>),\n",
       " DocToken(start=1463, stop=1464, text='я', pos='PRON', feats=<Nom,Sing,1>),\n",
       " DocToken(start=1465, stop=1471, text='слагал', pos='VERB', feats=<Imp,Ind,Sing,1,Pres,Fin,Act>),\n",
       " DocToken(start=1471, stop=1472, text=',', pos='PUNCT'),\n",
       " DocToken(start=1473, stop=1476, text='Как', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=1477, stop=1479, text='бы', pos='PART'),\n",
       " DocToken(start=1480, stop=1490, text='возвратясь', pos='VERB', feats=<Perf,Imp,Sing,2,Fin,Act>),\n",
       " DocToken(start=1491, stop=1493, text='ко', pos='ADP'),\n",
       " DocToken(start=1494, stop=1498, text='дням', pos='NOUN', feats=<Inan,Dat,Masc,Plur>),\n",
       " DocToken(start=1499, stop=1507, text='творенья', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=1507, stop=1508, text=',', pos='PUNCT'),\n",
       " DocToken(start=1509, stop=1510, text='И', pos='CCONJ'),\n",
       " DocToken(start=1511, stop=1519, text='вычислял', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1519, stop=1520, text=',', pos='PUNCT'),\n",
       " DocToken(start=1521, stop=1526, text='когда', pos='SCONJ'),\n",
       " DocToken(start=1527, stop=1536, text='последний', pos='ADJ', feats=<Nom,Pos,Masc,Sing>),\n",
       " DocToken(start=1537, stop=1541, text='галл', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=1542, stop=1547, text='Умрет', pos='VERB', feats=<Perf,Ind,Sing,3,Fut,Fin,Act>),\n",
       " DocToken(start=1547, stop=1548, text=',', pos='PUNCT'),\n",
       " DocToken(start=1549, stop=1551, text='не', pos='PART', feats=<Neg>),\n",
       " DocToken(start=1552, stop=1559, text='получив', pos='VERB', feats=<Perf,Past,Conv,Act>),\n",
       " DocToken(start=1560, stop=1574, text='удовлетворенья', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=1574, stop=1575, text='.', pos='PUNCT'),\n",
       " DocToken(start=1576, stop=1582, text='Далёко', pos='PROPN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=1583, stop=1584, text='в', pos='ADP'),\n",
       " DocToken(start=1585, stop=1593, text='пропасти', pos='NOUN', feats=<Inan,Loc,Masc,Sing>),\n",
       " DocToken(start=1594, stop=1599, text='шумит', pos='VERB', feats=<Imp,Ind,Sing,3,Pres,Fin,Act>),\n",
       " DocToken(start=1600, stop=1604, text='река', pos='NOUN', feats=<Inan,Nom,Fem,Sing>),\n",
       " DocToken(start=1604, stop=1605, text=',', pos='PUNCT'),\n",
       " DocToken(start=1606, stop=1607, text='К', pos='ADP'),\n",
       " DocToken(start=1608, stop=1611, text='ней', pos='PRON', feats=<Dat,Fem,Sing,3>),\n",
       " DocToken(start=1612, stop=1624, text='бело-красные', pos='VERB', feats=<Imp,Ind,Plur,3,Pres,Fin,Mid>),\n",
       " DocToken(start=1625, stop=1636, text='просыпались', pos='VERB', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=1637, stop=1641, text='мела', pos='NOUN', feats=<Anim,Acc,Masc,Sing>),\n",
       " DocToken(start=1641, stop=1642, text=',', pos='PUNCT'),\n",
       " DocToken(start=1643, stop=1644, text='Я', pos='PRON', feats=<Nom,Sing,1>),\n",
       " DocToken(start=1645, stop=1650, text='думал', pos='VERB', feats=<Imp,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1651, stop=1652, text='о', pos='ADP'),\n",
       " DocToken(start=1653, stop=1660, text='природе', pos='NOUN', feats=<Inan,Loc,Fem,Sing>),\n",
       " DocToken(start=1660, stop=1661, text=',', pos='PUNCT'),\n",
       " DocToken(start=1662, stop=1665, text='что', pos='SCONJ'),\n",
       " DocToken(start=1666, stop=1670, text='дика', pos='NOUN', feats=<Anim,Acc,Masc,Sing>),\n",
       " DocToken(start=1671, stop=1672, text='И', pos='PROPN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=1673, stop=1681, text='страшной', pos='ADJ', feats=<Ins,Pos,Fem,Sing>),\n",
       " DocToken(start=1682, stop=1691, text='прелестью', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=1692, stop=1696, text='мила', pos='NOUN', feats=<Anim,Nom,Fem,Sing>),\n",
       " DocToken(start=1696, stop=1697, text='.', pos='PUNCT'),\n",
       " DocToken(start=1698, stop=1699, text='Я', pos='PRON', feats=<Nom,Sing,1>),\n",
       " DocToken(start=1700, stop=1705, text='думал', pos='VERB', feats=<Imp,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1706, stop=1707, text='о', pos='ADP'),\n",
       " DocToken(start=1708, stop=1714, text='России', pos='PROPN', feats=<Inan,Loc,Fem,Sing>),\n",
       " DocToken(start=1714, stop=1715, text=',', pos='PUNCT'),\n",
       " DocToken(start=1716, stop=1723, text='которая', pos='PRON', feats=<Nom,Fem,Sing>),\n",
       " DocToken(start=1724, stop=1730, text='сменой', pos='NOUN', feats=<Inan,Ins,Fem,Sing>),\n",
       " DocToken(start=1731, stop=1736, text='тундр', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=1736, stop=1737, text=',', pos='PUNCT'),\n",
       " DocToken(start=1738, stop=1743, text='тайги', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=1743, stop=1744, text=',', pos='PUNCT'),\n",
       " DocToken(start=1745, stop=1751, text='степей', pos='NOUN', feats=<Inan,Gen,Masc,Plur>),\n",
       " DocToken(start=1752, stop=1758, text='Похожа', pos='PROPN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=1759, stop=1761, text='на', pos='ADP'),\n",
       " DocToken(start=1762, stop=1766, text='один', pos='NUM', feats=<Inan,Acc,Masc>),\n",
       " DocToken(start=1767, stop=1778, text='божественно', pos='ADJ', feats=<Inan,Acc,Pos,Masc,Sing>),\n",
       " DocToken(start=1779, stop=1787, text='звучащий', pos='VERB', feats=<Inan,Imp,Acc,Masc,Sing,Pres,Part,Act>),\n",
       " DocToken(start=1788, stop=1792, text='стих', pos='NOUN', feats=<Inan,Acc,Masc,Sing>),\n",
       " DocToken(start=1792, stop=1793, text=',', pos='PUNCT'),\n",
       " DocToken(start=1794, stop=1795, text='И', pos='CCONJ'),\n",
       " DocToken(start=1796, stop=1797, text='в', pos='ADP'),\n",
       " DocToken(start=1798, stop=1801, text='это', pos='DET', feats=<Inan,Acc,Neut,Sing>),\n",
       " DocToken(start=1802, stop=1807, text='время', pos='NOUN', feats=<Inan,Acc,Neut,Sing>),\n",
       " DocToken(start=1808, stop=1814, text='воздух', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=1815, stop=1826, text='освободился', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Mid>),\n",
       " DocToken(start=1827, stop=1829, text='от', pos='ADP'),\n",
       " DocToken(start=1830, stop=1835, text='цепей', pos='NOUN', feats=<Inan,Gen,Fem,Plur>),\n",
       " DocToken(start=1836, stop=1837, text='И', pos='CCONJ'),\n",
       " DocToken(start=1838, stop=1843, text='смолк', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=1843, stop=1844, text=',', pos='PUNCT'),\n",
       " DocToken(start=1845, stop=1850, text='погас', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1851, stop=1852, text='и', pos='CCONJ'),\n",
       " DocToken(start=1853, stop=1857, text='стих', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1857, stop=1858, text='.', pos='PUNCT'),\n",
       " DocToken(start=1859, stop=1860, text='И', pos='CCONJ'),\n",
       " DocToken(start=1861, stop=1866, text='вдруг', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=1867, stop=1869, text='на', pos='ADP'),\n",
       " DocToken(start=1870, stop=1877, text='веселой', pos='ADJ', feats=<Loc,Pos,Fem,Sing>),\n",
       " DocToken(start=1878, stop=1886, text='площадке', pos='NOUN', feats=<Inan,Loc,Fem,Sing>),\n",
       " DocToken(start=1886, stop=1887, text=',', pos='PUNCT'),\n",
       " DocToken(start=1888, stop=1895, text='Которая', pos='PRON', feats=<Nom,Fem,Sing>),\n",
       " DocToken(start=1895, stop=1896, text=',', pos='PUNCT'),\n",
       " DocToken(start=1897, stop=1899, text='на', pos='ADP'),\n",
       " DocToken(start=1900, stop=1909, text='городскую', pos='ADJ', feats=<Acc,Pos,Fem,Sing>),\n",
       " DocToken(start=1910, stop=1918, text='торговку', pos='NOUN', feats=<Inan,Acc,Fem,Sing>),\n",
       " DocToken(start=1919, stop=1926, text='цветами', pos='NOUN', feats=<Inan,Ins,Masc,Plur>),\n",
       " DocToken(start=1927, stop=1933, text='похожа', pos='ADJ', feats=<Pos,Fem,Sing,Short>),\n",
       " DocToken(start=1933, stop=1934, text=',', pos='PUNCT'),\n",
       " DocToken(start=1935, stop=1939, text='Зная', pos='VERB', feats=<Imp,Pres,Conv,Act>),\n",
       " DocToken(start=1939, stop=1940, text=',', pos='PUNCT'),\n",
       " DocToken(start=1941, stop=1944, text='как', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=1945, stop=1954, text='городские', pos='ADJ', feats=<Nom,Pos,Plur>),\n",
       " DocToken(start=1955, stop=1959, text='люди', pos='NOUN', feats=<Anim,Nom,Masc,Plur>),\n",
       " DocToken(start=1960, stop=1961, text='к', pos='ADP'),\n",
       " DocToken(start=1962, stop=1967, text='цвету', pos='NOUN', feats=<Inan,Dat,Masc,Sing>),\n",
       " DocToken(start=1968, stop=1973, text='падки', pos='NOUN', feats=<Inan,Gen,Masc,Sing>),\n",
       " DocToken(start=1973, stop=1974, text=',', pos='PUNCT'),\n",
       " DocToken(start=1975, stop=1981, text='Весело', pos='ADV', feats=<Pos>),\n",
       " DocToken(start=1982, stop=1992, text='предлагала', pos='VERB', feats=<Imp,Fem,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=1993, stop=1997, text='цвет', pos='NOUN', feats=<Inan,Acc,Masc,Sing>),\n",
       " DocToken(start=1998, stop=2002, text='свой', pos='DET', feats=<Acc,Masc,Sing>),\n",
       " DocToken(start=2003, stop=2011, text='прохожим', pos='NOUN', feats=<Anim,Dat,Masc,Plur>),\n",
       " DocToken(start=2011, stop=2012, text=',', pos='PUNCT'),\n",
       " DocToken(start=2013, stop=2014, text='—', pos='PUNCT'),\n",
       " DocToken(start=2015, stop=2021, text='Увидел', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=2022, stop=2023, text='я', pos='PRON', feats=<Nom,Sing,1>),\n",
       " DocToken(start=2024, stop=2030, text='камень', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=2030, stop=2031, text=',', pos='PUNCT'),\n",
       " DocToken(start=2032, stop=2037, text='камню', pos='NOUN', feats=<Inan,Dat,Masc,Sing>),\n",
       " DocToken(start=2038, stop=2046, text='подобный', pos='ADJ', feats=<Inan,Acc,Pos,Masc,Sing>),\n",
       " DocToken(start=2046, stop=2047, text=',', pos='PUNCT'),\n",
       " DocToken(start=2048, stop=2051, text='под', pos='ADP'),\n",
       " DocToken(start=2052, stop=2056, text='коим', pos='DET', feats=<Ins,Masc,Sing>),\n",
       " DocToken(start=2057, stop=2063, text='пророк', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=2064, stop=2073, text='Похоронен', pos='VERB', feats=<Perf,Masc,Sing,Past,Short,Part,Pass>),\n",
       " DocToken(start=2073, stop=2074, text=':', pos='PUNCT'),\n",
       " DocToken(start=2075, stop=2081, text='скошен', pos='NOUN', feats=<Anim,Nom,Masc,Sing>),\n",
       " DocToken(start=2082, stop=2084, text='он', pos='PRON', feats=<Nom,Masc,Sing,3>),\n",
       " DocToken(start=2085, stop=2088, text='над', pos='ADP'),\n",
       " DocToken(start=2089, stop=2095, text='плитой', pos='NOUN', feats=<Inan,Ins,Fem,Sing>),\n",
       " DocToken(start=2096, stop=2097, text='и', pos='CCONJ'),\n",
       " DocToken(start=2098, stop=2105, text='увенчан', pos='VERB', feats=<Perf,Masc,Sing,Past,Short,Part,Pass>),\n",
       " DocToken(start=2106, stop=2112, text='чалмой', pos='NOUN', feats=<Inan,Ins,Masc,Plur>),\n",
       " DocToken(start=2112, stop=2113, text='.', pos='PUNCT'),\n",
       " DocToken(start=2114, stop=2115, text='И', pos='CCONJ'),\n",
       " DocToken(start=2116, stop=2120, text='мощи', pos='NOUN', feats=<Inan,Nom,Fem,Plur>),\n",
       " DocToken(start=2121, stop=2130, text='старинной', pos='ADJ', feats=<Gen,Pos,Fem,Sing>),\n",
       " DocToken(start=2131, stop=2139, text='раковины', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=2139, stop=2140, text=',', pos='PUNCT'),\n",
       " DocToken(start=2141, stop=2149, text='изогнуты', pos='VERB', feats=<Perf,Ins,Plur,Past,Part,Pass>),\n",
       " DocToken(start=2150, stop=2151, text='в', pos='ADP'),\n",
       " DocToken(start=2152, stop=2160, text='козлиный', pos='ADJ', feats=<Inan,Acc,Pos,Masc,Sing>),\n",
       " DocToken(start=2161, stop=2164, text='рог', pos='NOUN', feats=<Inan,Acc,Masc,Sing>),\n",
       " DocToken(start=2164, stop=2165, text=',', pos='PUNCT'),\n",
       " DocToken(start=2166, stop=2168, text='На', pos='ADP'),\n",
       " DocToken(start=2169, stop=2174, text='камне', pos='NOUN', feats=<Inan,Loc,Masc,Sing>),\n",
       " DocToken(start=2175, stop=2184, text='выступали', pos='VERB', feats=<Imp,Ind,Plur,Past,Fin,Act>),\n",
       " DocToken(start=2184, stop=2185, text=';', pos='PUNCT'),\n",
       " DocToken(start=2186, stop=2194, text='казалось', pos='VERB', feats=<Imp,Neut,Ind,Sing,Past,Fin,Mid>),\n",
       " DocToken(start=2194, stop=2195, text=',', pos='PUNCT'),\n",
       " DocToken(start=2196, stop=2201, text='образ', pos='NOUN', feats=<Inan,Nom,Masc,Sing>),\n",
       " DocToken(start=2202, stop=2206, text='бога', pos='NOUN', feats=<Anim,Gen,Masc,Sing>),\n",
       " DocToken(start=2207, stop=2213, text='камень', pos='NOUN', feats=<Inan,Acc,Masc,Sing>),\n",
       " DocToken(start=2214, stop=2221, text='увенчал', pos='VERB', feats=<Perf,Masc,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=2222, stop=2225, text='мой', pos='DET', feats=<Nom,Masc,Sing>),\n",
       " DocToken(start=2225, stop=2226, text='.', pos='PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc.tag_morph(morph_tagger)\n",
    "display(doc.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла) Затем оценим accuracy для каждого теггера. Заметьте, что в разных системах имена тегов и части речи могут отличаться, – вам надо будет свести это всё к единому стандарту с помощью какой-то функции-конвертера и сравнить с вашим размеченным руками эталоном - тоже с помощью какого-то кода или функции.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составляю таблицы соответствий тегов stanza, pymorphy и natasha с тегами НКРЯ; нужно перевести все в один формат, чтобы иметь возможность измерить accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_from_stanza_to_gr_table = {\n",
    "            \"ADJ\": \"A\",\n",
    "            \"ADP\": \"PR\",\n",
    "            \"ADV\": \"ADV\",\n",
    "            \"AUX\": \"AUX\",\n",
    "            \"CCONJ\": \"CONJ\",\n",
    "            \"DET\": \"DET\",\n",
    "            \"INTJ\": \"INTJ\",\n",
    "            \"NOUN\": \"S\",\n",
    "            \"NUM\": \"NUM\",\n",
    "            \"PART\": \"PART\",\n",
    "            \"PRON\": \"PRO\",\n",
    "            \"PROPN\": \"persn\",\n",
    "            \"SCONJ\": \"CONJ\",\n",
    "            \"VERB\": \"V\",\n",
    "            \"X\": \"X\",\n",
    "            \"PUNCT\": \"PUNCT\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_from_pymorphy_to_gr_table = {\n",
    "            \"ADJ\": \"A\",\n",
    "            \"ADP\": \"PR\",\n",
    "            \"ADV\": \"ADV\",\n",
    "            \"AUX\": \"AUX\",\n",
    "            \"CCONJ\": \"CONJ\",\n",
    "            \"DET\": \"DET\",\n",
    "            \"INTJ\": \"INTJ\",\n",
    "            \"NOUN\": \"S\",\n",
    "            \"NUM\": \"NUM\",\n",
    "            \"PART\": \"PART\",\n",
    "            \"PRON\": \"PRO\",\n",
    "            \"PROPN\": \"persn\",\n",
    "            \"SCONJ\": \"CONJ\",\n",
    "            \"VERB\": \"V\",\n",
    "            \"X\": \"X\",\n",
    "            \"PUNCT\": \"PUNCT\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_from_natasha_to_gr_table = {\n",
    "            \"ADJ\": \"A\",\n",
    "            \"ADP\": \"PR\",\n",
    "            \"ADV\": \"ADV\",\n",
    "            \"AUX\": \"AUX\",\n",
    "            \"CCONJ\": \"CONJ\",\n",
    "            \"DET\": \"DET\",\n",
    "            \"INTJ\": \"INTJ\",\n",
    "            \"NOUN\": \"S\",\n",
    "            \"NUM\": \"NUM\",\n",
    "            \"PART\": \"PART\",\n",
    "            \"PRON\": \"PRO\",\n",
    "            \"PROPN\": \"persn\",\n",
    "            \"SCONJ\": \"CONJ\",\n",
    "            \"VERB\": \"V\",\n",
    "            \"X\": \"X\",\n",
    "            \"PUNCT\": \"PUNCT\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потом нужно сделать функцию для перевода тегов в один формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# потом делаем что-то такое и получаем ответ\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
